{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1634186,"sourceType":"datasetVersion","datasetId":966140},{"sourceId":81892,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":68819,"modelId":93969},{"sourceId":82085,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":68971,"modelId":94103}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install keras==2.15.0","metadata":{"execution":{"iopub.status.busy":"2024-07-25T07:51:33.025897Z","iopub.execute_input":"2024-07-25T07:51:33.026614Z","iopub.status.idle":"2024-07-25T07:51:50.131361Z","shell.execute_reply.started":"2024-07-25T07:51:33.026576Z","shell.execute_reply":"2024-07-25T07:51:50.129923Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting keras==2.15.0\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install patchify","metadata":{"execution":{"iopub.status.busy":"2024-07-25T07:51:50.133777Z","iopub.execute_input":"2024-07-25T07:51:50.134226Z","iopub.status.idle":"2024-07-25T07:52:02.786697Z","shell.execute_reply.started":"2024-07-25T07:51:50.134183Z","shell.execute_reply":"2024-07-25T07:52:02.785403Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting patchify\n  Downloading patchify-0.2.3-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from patchify) (1.26.4)\nDownloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\nInstalling collected packages: patchify\nSuccessfully installed patchify-0.2.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom math import log2\nimport tensorflow as tf\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.models import Model\n\ndef mlp_block(inputs, config):\n    x = layers.Dense(config[\"mlp_units\"], activation=\"gelu\")(inputs)\n    x = layers.Dropout(config[\"dropout_rate\"])(x)\n    x = layers.Dense(config[\"hidden_units\"])(x)\n    x = layers.Dropout(config[\"dropout_rate\"])(x)\n    return x\n\ndef transformer_block(inputs, config):\n    skip_conn1 = inputs\n    x = layers.LayerNormalization()(inputs)\n    x = layers.MultiHeadAttention(\n        num_heads=config[\"heads\"], key_dim=config[\"hidden_units\"]\n    )(x, x)\n    x = layers.Add()([x, skip_conn1])\n\n    skip_conn2 = x\n    x = layers.LayerNormalization()(x)\n    x = mlp_block(x, config)\n    x = layers.Add()([x, skip_conn2])\n\n    return x\n\ndef conv_layer_block(inputs, filters, kernel_size=3):\n    x = layers.Conv2D(filters, kernel_size=kernel_size, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    return x\n\ndef upconv_layer_block(inputs, filters, strides=2):\n    x = layers.Conv2DTranspose(filters, kernel_size=2, padding=\"same\", strides=strides)(inputs)\n    return x\n\ndef build_custom_unet(config):\n  \n    input_shape = (config[\"num_patches\"], config[\"patch_size\"] * config[\"patch_size\"] * config[\"channels\"])\n    inputs = layers.Input(input_shape)\n\n        \n    patch_embedding = layers.Dense(config[\"hidden_units\"])(inputs)  # (None, 256, 768)\n\n    positions = tf.range(start=0, limit=config[\"num_patches\"], delta=1)  # (256,)\n    pos_embedding = layers.Embedding(input_dim=config[\"num_patches\"], output_dim=config[\"hidden_units\"])(positions)  # (256, 768)\n    x = patch_embedding + pos_embedding  # (None, 256, 768)\n\n    #Transformer Encoder\n    skip_conn_indices = [3, 6, 9, 12]\n    skip_connections = []\n\n    for i in range(1, config[\"layers\"] + 1):\n        x = transformer_block(x, config)\n\n        if i in skip_conn_indices:\n            skip_connections.append(x)\n\n   \n    z3, z6, z9, z12 = skip_connections\n\n  \n    z0 = layers.Reshape((config[\"img_size\"], config[\"img_size\"], config[\"channels\"]))(inputs)\n\n    shape = (\n        config[\"img_size\"] // config[\"patch_size\"],\n        config[\"img_size\"] // config[\"patch_size\"],\n        config[\"hidden_units\"]\n    )\n    z3 = layers.Reshape(shape)(z3)\n    z6 = layers.Reshape(shape)(z6)\n    z9 = layers.Reshape(shape)(z9)\n    z12 = layers.Reshape(shape)(z12)\n\n   \n    total_upscale_factor = int(log2(config[\"patch_size\"]))\n    upscale = total_upscale_factor - 4\n\n    if upscale >= 2:  # Patch size 16 or greater\n        z3 = upconv_layer_block(z3, z3.shape[-1], strides=2 ** upscale)\n        z6 = upconv_layer_block(z6, z6.shape[-1], strides=2 ** upscale)\n        z9 = upconv_layer_block(z9, z9.shape[-1], strides=2 ** upscale)\n        z12 = upconv_layer_block(z12, z12.shape[-1], strides=2 ** upscale)\n\n    if upscale < 0:  # Patch size less than 16\n        p = 2 ** abs(upscale)\n        z3 = layers.MaxPool2D((p, p))(z3)\n        z6 = layers.MaxPool2D((p, p))(z6)\n        z9 = layers.MaxPool2D((p, p))(z9)\n        z12 = layers.MaxPool2D((p, p))(z12)\n\n    #Decoder 1\n    x = upconv_layer_block(z12, 128)\n\n    s = upconv_layer_block(z9, 128)\n    s = conv_layer_block(s, 128)\n\n    x = layers.Concatenate()([x, s])\n    x = conv_layer_block(x, 128)\n    x = conv_layer_block(x, 128)\n\n    # Decoder 2 \n    x = upconv_layer_block(x, 64)\n\n    s = upconv_layer_block(z6, 64)\n    s = conv_layer_block(s, 64)\n    s = upconv_layer_block(s, 64)\n    s = conv_layer_block(s, 64)\n\n    x = layers.Concatenate()([x, s])\n    x = conv_layer_block(x, 64)\n    x = conv_layer_block(x, 64)\n\n    #Decoder 3\n    x = upconv_layer_block(x, 32)\n\n    s = upconv_layer_block(z3, 32)\n    s = conv_layer_block(s, 32)\n    s = upconv_layer_block(s, 32)\n    s = conv_layer_block(s, 32)\n    s = upconv_layer_block(s, 32)\n    s = conv_layer_block(s, 32)\n\n    x = layers.Concatenate()([x, s])\n    x = conv_layer_block(x, 32)\n    x = conv_layer_block(x, 32)\n\n    #Decoder 4 \n    x = upconv_layer_block(x, 16)\n\n    s = conv_layer_block(z0, 16)\n    s = conv_layer_block(s, 16)\n\n    x = layers.Concatenate()([x, s])\n    x = conv_layer_block(x, 16)\n    x = conv_layer_block(x, 16)\n\n    #output\n    outputs = layers.Conv2D(1, kernel_size=1, padding=\"same\", activation=\"sigmoid\")(x)\n\n    return Model(inputs, outputs, name=\"Custom_UNETR_2D\")\n\nif __name__ == \"__main__\":\n    config = {}\n    config[\"img_size\"] = 512\n    config[\"layers\"] = 12\n    config[\"hidden_units\"] = 64\n    config[\"mlp_units\"] = 128\n    config[\"heads\"] = 6\n    config[\"dropout_rate\"] = 0.1\n    config[\"patch_size\"] = 512\n    config[\"num_patches\"] = (config[\"img_size\"] ** 2) // (config[\"patch_size\"] ** 2)\n    config[\"channels\"] = 3\n\n    model = build_custom_unet(config)\n    model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T05:37:32.912686Z","iopub.execute_input":"2024-07-25T05:37:32.913131Z","iopub.status.idle":"2024-07-25T05:37:41.541519Z","shell.execute_reply.started":"2024-07-25T05:37:32.913088Z","shell.execute_reply":"2024-07-25T05:37:41.540343Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-07-25 05:37:33.380352: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-25 05:37:33.380420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-25 05:37:33.382137: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Model: \"Custom_UNETR_2D\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 1, 786432)]          0         []                            \n                                                                                                  \n dense (Dense)               (None, 1, 64)                5033171   ['input_1[0][0]']             \n                                                          2                                       \n                                                                                                  \n tf.__operators__.add (TFOp  (None, 1, 64)                0         ['dense[0][0]']               \n Lambda)                                                                                          \n                                                                                                  \n layer_normalization (Layer  (None, 1, 64)                128       ['tf.__operators__.add[0][0]']\n Normalization)                                                                                   \n                                                                                                  \n multi_head_attention (Mult  (None, 1, 64)                99520     ['layer_normalization[0][0]', \n iHeadAttention)                                                     'layer_normalization[0][0]'] \n                                                                                                  \n add (Add)                   (None, 1, 64)                0         ['multi_head_attention[0][0]',\n                                                                     'tf.__operators__.add[0][0]']\n                                                                                                  \n layer_normalization_1 (Lay  (None, 1, 64)                128       ['add[0][0]']                 \n erNormalization)                                                                                 \n                                                                                                  \n dense_1 (Dense)             (None, 1, 128)               8320      ['layer_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n dropout (Dropout)           (None, 1, 128)               0         ['dense_1[0][0]']             \n                                                                                                  \n dense_2 (Dense)             (None, 1, 64)                8256      ['dropout[0][0]']             \n                                                                                                  \n dropout_1 (Dropout)         (None, 1, 64)                0         ['dense_2[0][0]']             \n                                                                                                  \n add_1 (Add)                 (None, 1, 64)                0         ['dropout_1[0][0]',           \n                                                                     'add[0][0]']                 \n                                                                                                  \n layer_normalization_2 (Lay  (None, 1, 64)                128       ['add_1[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n multi_head_attention_1 (Mu  (None, 1, 64)                99520     ['layer_normalization_2[0][0]'\n ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]\n                                                                    ']                            \n                                                                                                  \n add_2 (Add)                 (None, 1, 64)                0         ['multi_head_attention_1[0][0]\n                                                                    ',                            \n                                                                     'add_1[0][0]']               \n                                                                                                  \n layer_normalization_3 (Lay  (None, 1, 64)                128       ['add_2[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n dense_3 (Dense)             (None, 1, 128)               8320      ['layer_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n dropout_2 (Dropout)         (None, 1, 128)               0         ['dense_3[0][0]']             \n                                                                                                  \n dense_4 (Dense)             (None, 1, 64)                8256      ['dropout_2[0][0]']           \n                                                                                                  \n dropout_3 (Dropout)         (None, 1, 64)                0         ['dense_4[0][0]']             \n                                                                                                  \n add_3 (Add)                 (None, 1, 64)                0         ['dropout_3[0][0]',           \n                                                                     'add_2[0][0]']               \n                                                                                                  \n layer_normalization_4 (Lay  (None, 1, 64)                128       ['add_3[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n multi_head_attention_2 (Mu  (None, 1, 64)                99520     ['layer_normalization_4[0][0]'\n ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n                                                                    ']                            \n                                                                                                  \n add_4 (Add)                 (None, 1, 64)                0         ['multi_head_attention_2[0][0]\n                                                                    ',                            \n                                                                     'add_3[0][0]']               \n                                                                                                  \n layer_normalization_5 (Lay  (None, 1, 64)                128       ['add_4[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n dense_5 (Dense)             (None, 1, 128)               8320      ['layer_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n dropout_4 (Dropout)         (None, 1, 128)               0         ['dense_5[0][0]']             \n                                                                                                  \n dense_6 (Dense)             (None, 1, 64)                8256      ['dropout_4[0][0]']           \n                                                                                                  \n dropout_5 (Dropout)         (None, 1, 64)                0         ['dense_6[0][0]']             \n                                                                                                  \n add_5 (Add)                 (None, 1, 64)                0         ['dropout_5[0][0]',           \n                                                                     'add_4[0][0]']               \n                                                                                                  \n layer_normalization_6 (Lay  (None, 1, 64)                128       ['add_5[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n multi_head_attention_3 (Mu  (None, 1, 64)                99520     ['layer_normalization_6[0][0]'\n ltiHeadAttention)                                                  , 'layer_normalization_6[0][0]\n                                                                    ']                            \n                                                                                                  \n add_6 (Add)                 (None, 1, 64)                0         ['multi_head_attention_3[0][0]\n                                                                    ',                            \n                                                                     'add_5[0][0]']               \n                                                                                                  \n layer_normalization_7 (Lay  (None, 1, 64)                128       ['add_6[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n dense_7 (Dense)             (None, 1, 128)               8320      ['layer_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n dropout_6 (Dropout)         (None, 1, 128)               0         ['dense_7[0][0]']             \n                                                                                                  \n dense_8 (Dense)             (None, 1, 64)                8256      ['dropout_6[0][0]']           \n                                                                                                  \n dropout_7 (Dropout)         (None, 1, 64)                0         ['dense_8[0][0]']             \n                                                                                                  \n add_7 (Add)                 (None, 1, 64)                0         ['dropout_7[0][0]',           \n                                                                     'add_6[0][0]']               \n                                                                                                  \n layer_normalization_8 (Lay  (None, 1, 64)                128       ['add_7[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n multi_head_attention_4 (Mu  (None, 1, 64)                99520     ['layer_normalization_8[0][0]'\n ltiHeadAttention)                                                  , 'layer_normalization_8[0][0]\n                                                                    ']                            \n                                                                                                  \n add_8 (Add)                 (None, 1, 64)                0         ['multi_head_attention_4[0][0]\n                                                                    ',                            \n                                                                     'add_7[0][0]']               \n                                                                                                  \n layer_normalization_9 (Lay  (None, 1, 64)                128       ['add_8[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n dense_9 (Dense)             (None, 1, 128)               8320      ['layer_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n dropout_8 (Dropout)         (None, 1, 128)               0         ['dense_9[0][0]']             \n                                                                                                  \n dense_10 (Dense)            (None, 1, 64)                8256      ['dropout_8[0][0]']           \n                                                                                                  \n dropout_9 (Dropout)         (None, 1, 64)                0         ['dense_10[0][0]']            \n                                                                                                  \n add_9 (Add)                 (None, 1, 64)                0         ['dropout_9[0][0]',           \n                                                                     'add_8[0][0]']               \n                                                                                                  \n layer_normalization_10 (La  (None, 1, 64)                128       ['add_9[0][0]']               \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_5 (Mu  (None, 1, 64)                99520     ['layer_normalization_10[0][0]\n ltiHeadAttention)                                                  ',                            \n                                                                     'layer_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n add_10 (Add)                (None, 1, 64)                0         ['multi_head_attention_5[0][0]\n                                                                    ',                            \n                                                                     'add_9[0][0]']               \n                                                                                                  \n layer_normalization_11 (La  (None, 1, 64)                128       ['add_10[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_11 (Dense)            (None, 1, 128)               8320      ['layer_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_10 (Dropout)        (None, 1, 128)               0         ['dense_11[0][0]']            \n                                                                                                  \n dense_12 (Dense)            (None, 1, 64)                8256      ['dropout_10[0][0]']          \n                                                                                                  \n dropout_11 (Dropout)        (None, 1, 64)                0         ['dense_12[0][0]']            \n                                                                                                  \n add_11 (Add)                (None, 1, 64)                0         ['dropout_11[0][0]',          \n                                                                     'add_10[0][0]']              \n                                                                                                  \n layer_normalization_12 (La  (None, 1, 64)                128       ['add_11[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_6 (Mu  (None, 1, 64)                99520     ['layer_normalization_12[0][0]\n ltiHeadAttention)                                                  ',                            \n                                                                     'layer_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n add_12 (Add)                (None, 1, 64)                0         ['multi_head_attention_6[0][0]\n                                                                    ',                            \n                                                                     'add_11[0][0]']              \n                                                                                                  \n layer_normalization_13 (La  (None, 1, 64)                128       ['add_12[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_13 (Dense)            (None, 1, 128)               8320      ['layer_normalization_13[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_12 (Dropout)        (None, 1, 128)               0         ['dense_13[0][0]']            \n                                                                                                  \n dense_14 (Dense)            (None, 1, 64)                8256      ['dropout_12[0][0]']          \n                                                                                                  \n dropout_13 (Dropout)        (None, 1, 64)                0         ['dense_14[0][0]']            \n                                                                                                  \n add_13 (Add)                (None, 1, 64)                0         ['dropout_13[0][0]',          \n                                                                     'add_12[0][0]']              \n                                                                                                  \n layer_normalization_14 (La  (None, 1, 64)                128       ['add_13[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_7 (Mu  (None, 1, 64)                99520     ['layer_normalization_14[0][0]\n ltiHeadAttention)                                                  ',                            \n                                                                     'layer_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n add_14 (Add)                (None, 1, 64)                0         ['multi_head_attention_7[0][0]\n                                                                    ',                            \n                                                                     'add_13[0][0]']              \n                                                                                                  \n layer_normalization_15 (La  (None, 1, 64)                128       ['add_14[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_15 (Dense)            (None, 1, 128)               8320      ['layer_normalization_15[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_14 (Dropout)        (None, 1, 128)               0         ['dense_15[0][0]']            \n                                                                                                  \n dense_16 (Dense)            (None, 1, 64)                8256      ['dropout_14[0][0]']          \n                                                                                                  \n dropout_15 (Dropout)        (None, 1, 64)                0         ['dense_16[0][0]']            \n                                                                                                  \n add_15 (Add)                (None, 1, 64)                0         ['dropout_15[0][0]',          \n                                                                     'add_14[0][0]']              \n                                                                                                  \n layer_normalization_16 (La  (None, 1, 64)                128       ['add_15[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_8 (Mu  (None, 1, 64)                99520     ['layer_normalization_16[0][0]\n ltiHeadAttention)                                                  ',                            \n                                                                     'layer_normalization_16[0][0]\n                                                                    ']                            \n                                                                                                  \n add_16 (Add)                (None, 1, 64)                0         ['multi_head_attention_8[0][0]\n                                                                    ',                            \n                                                                     'add_15[0][0]']              \n                                                                                                  \n layer_normalization_17 (La  (None, 1, 64)                128       ['add_16[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_17 (Dense)            (None, 1, 128)               8320      ['layer_normalization_17[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_16 (Dropout)        (None, 1, 128)               0         ['dense_17[0][0]']            \n                                                                                                  \n dense_18 (Dense)            (None, 1, 64)                8256      ['dropout_16[0][0]']          \n                                                                                                  \n dropout_17 (Dropout)        (None, 1, 64)                0         ['dense_18[0][0]']            \n                                                                                                  \n add_17 (Add)                (None, 1, 64)                0         ['dropout_17[0][0]',          \n                                                                     'add_16[0][0]']              \n                                                                                                  \n layer_normalization_18 (La  (None, 1, 64)                128       ['add_17[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_9 (Mu  (None, 1, 64)                99520     ['layer_normalization_18[0][0]\n ltiHeadAttention)                                                  ',                            \n                                                                     'layer_normalization_18[0][0]\n                                                                    ']                            \n                                                                                                  \n add_18 (Add)                (None, 1, 64)                0         ['multi_head_attention_9[0][0]\n                                                                    ',                            \n                                                                     'add_17[0][0]']              \n                                                                                                  \n layer_normalization_19 (La  (None, 1, 64)                128       ['add_18[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_19 (Dense)            (None, 1, 128)               8320      ['layer_normalization_19[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_18 (Dropout)        (None, 1, 128)               0         ['dense_19[0][0]']            \n                                                                                                  \n dense_20 (Dense)            (None, 1, 64)                8256      ['dropout_18[0][0]']          \n                                                                                                  \n dropout_19 (Dropout)        (None, 1, 64)                0         ['dense_20[0][0]']            \n                                                                                                  \n add_19 (Add)                (None, 1, 64)                0         ['dropout_19[0][0]',          \n                                                                     'add_18[0][0]']              \n                                                                                                  \n layer_normalization_20 (La  (None, 1, 64)                128       ['add_19[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_10 (M  (None, 1, 64)                99520     ['layer_normalization_20[0][0]\n ultiHeadAttention)                                                 ',                            \n                                                                     'layer_normalization_20[0][0]\n                                                                    ']                            \n                                                                                                  \n add_20 (Add)                (None, 1, 64)                0         ['multi_head_attention_10[0][0\n                                                                    ]',                           \n                                                                     'add_19[0][0]']              \n                                                                                                  \n layer_normalization_21 (La  (None, 1, 64)                128       ['add_20[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_21 (Dense)            (None, 1, 128)               8320      ['layer_normalization_21[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_20 (Dropout)        (None, 1, 128)               0         ['dense_21[0][0]']            \n                                                                                                  \n dense_22 (Dense)            (None, 1, 64)                8256      ['dropout_20[0][0]']          \n                                                                                                  \n dropout_21 (Dropout)        (None, 1, 64)                0         ['dense_22[0][0]']            \n                                                                                                  \n add_21 (Add)                (None, 1, 64)                0         ['dropout_21[0][0]',          \n                                                                     'add_20[0][0]']              \n                                                                                                  \n layer_normalization_22 (La  (None, 1, 64)                128       ['add_21[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_11 (M  (None, 1, 64)                99520     ['layer_normalization_22[0][0]\n ultiHeadAttention)                                                 ',                            \n                                                                     'layer_normalization_22[0][0]\n                                                                    ']                            \n                                                                                                  \n add_22 (Add)                (None, 1, 64)                0         ['multi_head_attention_11[0][0\n                                                                    ]',                           \n                                                                     'add_21[0][0]']              \n                                                                                                  \n layer_normalization_23 (La  (None, 1, 64)                128       ['add_22[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_23 (Dense)            (None, 1, 128)               8320      ['layer_normalization_23[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_22 (Dropout)        (None, 1, 128)               0         ['dense_23[0][0]']            \n                                                                                                  \n dense_24 (Dense)            (None, 1, 64)                8256      ['dropout_22[0][0]']          \n                                                                                                  \n reshape_3 (Reshape)         (None, 1, 1, 64)             0         ['add_17[0][0]']              \n                                                                                                  \n dropout_23 (Dropout)        (None, 1, 64)                0         ['dense_24[0][0]']            \n                                                                                                  \n conv2d_transpose_2 (Conv2D  (None, 32, 32, 64)           16448     ['reshape_3[0][0]']           \n Transpose)                                                                                       \n                                                                                                  \n add_23 (Add)                (None, 1, 64)                0         ['dropout_23[0][0]',          \n                                                                     'add_22[0][0]']              \n                                                                                                  \n conv2d_transpose_5 (Conv2D  (None, 64, 64, 128)          32896     ['conv2d_transpose_2[0][0]']  \n Transpose)                                                                                       \n                                                                                                  \n reshape_4 (Reshape)         (None, 1, 1, 64)             0         ['add_23[0][0]']              \n                                                                                                  \n conv2d (Conv2D)             (None, 64, 64, 128)          147584    ['conv2d_transpose_5[0][0]']  \n                                                                                                  \n conv2d_transpose_3 (Conv2D  (None, 32, 32, 64)           16448     ['reshape_4[0][0]']           \n Transpose)                                                                                       \n                                                                                                  \n batch_normalization (Batch  (None, 64, 64, 128)          512       ['conv2d[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n reshape_2 (Reshape)         (None, 1, 1, 64)             0         ['add_11[0][0]']              \n                                                                                                  \n conv2d_transpose_4 (Conv2D  (None, 64, 64, 128)          32896     ['conv2d_transpose_3[0][0]']  \n Transpose)                                                                                       \n                                                                                                  \n re_lu (ReLU)                (None, 64, 64, 128)          0         ['batch_normalization[0][0]'] \n                                                                                                  \n conv2d_transpose_1 (Conv2D  (None, 32, 32, 64)           16448     ['reshape_2[0][0]']           \n Transpose)                                                                                       \n                                                                                                  \n concatenate (Concatenate)   (None, 64, 64, 256)          0         ['conv2d_transpose_4[0][0]',  \n                                                                     're_lu[0][0]']               \n                                                                                                  \n conv2d_transpose_7 (Conv2D  (None, 64, 64, 64)           16448     ['conv2d_transpose_1[0][0]']  \n Transpose)                                                                                       \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 64, 64, 128)          295040    ['concatenate[0][0]']         \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d_transpose_7[0][0]']  \n                                                                                                  \n batch_normalization_1 (Bat  (None, 64, 64, 128)          512       ['conv2d_1[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_3 (Bat  (None, 64, 64, 64)           256       ['conv2d_3[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n reshape_1 (Reshape)         (None, 1, 1, 64)             0         ['add_5[0][0]']               \n                                                                                                  \n re_lu_1 (ReLU)              (None, 64, 64, 128)          0         ['batch_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n re_lu_3 (ReLU)              (None, 64, 64, 64)           0         ['batch_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_transpose (Conv2DTr  (None, 32, 32, 64)           16448     ['reshape_1[0][0]']           \n anspose)                                                                                         \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 64, 64, 128)          147584    ['re_lu_1[0][0]']             \n                                                                                                  \n conv2d_transpose_8 (Conv2D  (None, 128, 128, 64)         16448     ['re_lu_3[0][0]']             \n Transpose)                                                                                       \n                                                                                                  \n conv2d_transpose_10 (Conv2  (None, 64, 64, 32)           8224      ['conv2d_transpose[0][0]']    \n DTranspose)                                                                                      \n                                                                                                  \n batch_normalization_2 (Bat  (None, 64, 64, 128)          512       ['conv2d_2[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 128, 128, 64)         36928     ['conv2d_transpose_8[0][0]']  \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 64, 64, 32)           9248      ['conv2d_transpose_10[0][0]'] \n                                                                                                  \n re_lu_2 (ReLU)              (None, 64, 64, 128)          0         ['batch_normalization_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n batch_normalization_4 (Bat  (None, 128, 128, 64)         256       ['conv2d_4[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_7 (Bat  (None, 64, 64, 32)           128       ['conv2d_7[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n conv2d_transpose_6 (Conv2D  (None, 128, 128, 64)         32832     ['re_lu_2[0][0]']             \n Transpose)                                                                                       \n                                                                                                  \n re_lu_4 (ReLU)              (None, 128, 128, 64)         0         ['batch_normalization_4[0][0]'\n                                                                    ]                             \n                                                                                                  \n re_lu_7 (ReLU)              (None, 64, 64, 32)           0         ['batch_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n concatenate_1 (Concatenate  (None, 128, 128, 128)        0         ['conv2d_transpose_6[0][0]',  \n )                                                                   're_lu_4[0][0]']             \n                                                                                                  \n conv2d_transpose_11 (Conv2  (None, 128, 128, 32)         4128      ['re_lu_7[0][0]']             \n DTranspose)                                                                                      \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 128, 128, 64)         73792     ['concatenate_1[0][0]']       \n                                                                                                  \n conv2d_8 (Conv2D)           (None, 128, 128, 32)         9248      ['conv2d_transpose_11[0][0]'] \n                                                                                                  \n batch_normalization_5 (Bat  (None, 128, 128, 64)         256       ['conv2d_5[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_8 (Bat  (None, 128, 128, 32)         128       ['conv2d_8[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_5 (ReLU)              (None, 128, 128, 64)         0         ['batch_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n re_lu_8 (ReLU)              (None, 128, 128, 32)         0         ['batch_normalization_8[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 128, 128, 64)         36928     ['re_lu_5[0][0]']             \n                                                                                                  \n conv2d_transpose_12 (Conv2  (None, 256, 256, 32)         4128      ['re_lu_8[0][0]']             \n DTranspose)                                                                                      \n                                                                                                  \n batch_normalization_6 (Bat  (None, 128, 128, 64)         256       ['conv2d_6[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n conv2d_9 (Conv2D)           (None, 256, 256, 32)         9248      ['conv2d_transpose_12[0][0]'] \n                                                                                                  \n re_lu_6 (ReLU)              (None, 128, 128, 64)         0         ['batch_normalization_6[0][0]'\n                                                                    ]                             \n                                                                                                  \n batch_normalization_9 (Bat  (None, 256, 256, 32)         128       ['conv2d_9[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n conv2d_transpose_9 (Conv2D  (None, 256, 256, 32)         8224      ['re_lu_6[0][0]']             \n Transpose)                                                                                       \n                                                                                                  \n re_lu_9 (ReLU)              (None, 256, 256, 32)         0         ['batch_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n concatenate_2 (Concatenate  (None, 256, 256, 64)         0         ['conv2d_transpose_9[0][0]',  \n )                                                                   're_lu_9[0][0]']             \n                                                                                                  \n conv2d_10 (Conv2D)          (None, 256, 256, 32)         18464     ['concatenate_2[0][0]']       \n                                                                                                  \n reshape (Reshape)           (None, 512, 512, 3)          0         ['input_1[0][0]']             \n                                                                                                  \n batch_normalization_10 (Ba  (None, 256, 256, 32)         128       ['conv2d_10[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 512, 512, 16)         448       ['reshape[0][0]']             \n                                                                                                  \n re_lu_10 (ReLU)             (None, 256, 256, 32)         0         ['batch_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_12 (Ba  (None, 512, 512, 16)         64        ['conv2d_12[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_11 (Conv2D)          (None, 256, 256, 32)         9248      ['re_lu_10[0][0]']            \n                                                                                                  \n re_lu_12 (ReLU)             (None, 512, 512, 16)         0         ['batch_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_11 (Ba  (None, 256, 256, 32)         128       ['conv2d_11[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 512, 512, 16)         2320      ['re_lu_12[0][0]']            \n                                                                                                  \n re_lu_11 (ReLU)             (None, 256, 256, 32)         0         ['batch_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_13 (Ba  (None, 512, 512, 16)         64        ['conv2d_13[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_transpose_13 (Conv2  (None, 512, 512, 16)         2064      ['re_lu_11[0][0]']            \n DTranspose)                                                                                      \n                                                                                                  \n re_lu_13 (ReLU)             (None, 512, 512, 16)         0         ['batch_normalization_13[0][0]\n                                                                    ']                            \n                                                                                                  \n concatenate_3 (Concatenate  (None, 512, 512, 32)         0         ['conv2d_transpose_13[0][0]', \n )                                                                   're_lu_13[0][0]']            \n                                                                                                  \n conv2d_14 (Conv2D)          (None, 512, 512, 16)         4624      ['concatenate_3[0][0]']       \n                                                                                                  \n batch_normalization_14 (Ba  (None, 512, 512, 16)         64        ['conv2d_14[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_14 (ReLU)             (None, 512, 512, 16)         0         ['batch_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_15 (Conv2D)          (None, 512, 512, 16)         2320      ['re_lu_14[0][0]']            \n                                                                                                  \n batch_normalization_15 (Ba  (None, 512, 512, 16)         64        ['conv2d_15[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_15 (ReLU)             (None, 512, 512, 16)         0         ['batch_normalization_15[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_16 (Conv2D)          (None, 512, 512, 1)          17        ['re_lu_15[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 52795441 (201.40 MB)\nTrainable params: 52793713 (201.39 MB)\nNon-trainable params: 1728 (6.75 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2024-07-25T05:37:41.542962Z","iopub.execute_input":"2024-07-25T05:37:41.543329Z","iopub.status.idle":"2024-07-25T05:37:41.550005Z","shell.execute_reply.started":"2024-07-25T05:37:41.543287Z","shell.execute_reply":"2024-07-25T05:37:41.548747Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\nsmooth = 1e-15\ndef dice_coef(y_true, y_pred):\n    y_true = tf.keras.layers.Flatten()(y_true)\n    y_pred = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true * y_pred)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T07:53:29.331885Z","iopub.execute_input":"2024-07-25T07:53:29.332427Z","iopub.status.idle":"2024-07-25T07:53:42.536340Z","shell.execute_reply.started":"2024-07-25T07:53:29.332386Z","shell.execute_reply":"2024-07-25T07:53:42.535250Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-07-25 07:53:31.456347: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-25 07:53:31.456482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-25 07:53:31.609289: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom math import log2\nimport tensorflow as tf\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.models import Model\n\ndef mlp_block(inputs, config):\n    x = layers.Dense(config[\"mlp_units\"], activation=\"gelu\")(inputs)\n    x = layers.Dropout(config[\"dropout_rate\"])(x)\n    x = layers.Dense(config[\"hidden_units\"])(x)\n    x = layers.Dropout(config[\"dropout_rate\"])(x)\n    return x\n\ndef transformer_block(inputs, config):\n    skip_conn1 = inputs\n    x = layers.LayerNormalization()(inputs)\n    x = layers.MultiHeadAttention(\n        num_heads=config[\"heads\"], key_dim=config[\"hidden_units\"]\n    )(x, x)\n    x = layers.Add()([x, skip_conn1])\n\n    skip_conn2 = x\n    x = layers.LayerNormalization()(x)\n    x = mlp_block(x, config)\n    x = layers.Add()([x, skip_conn2])\n\n    return x\n\ndef conv_layer_block(inputs, filters, kernel_size=3):\n    x = layers.Conv2D(filters, kernel_size=kernel_size, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    return x\n\ndef upconv_layer_block(inputs, filters, strides=2):\n    x = layers.Conv2DTranspose(filters, kernel_size=2, padding=\"same\", strides=strides)(inputs)\n    return x\n\ndef build_custom_unet(config):\n  \n    input_shape = (config[\"num_patches\"], config[\"patch_size\"] * config[\"patch_size\"] * config[\"channels\"])\n    inputs = layers.Input(input_shape)\n\n        \n    patch_embedding = layers.Dense(config[\"hidden_units\"])(inputs)  # (None, 256, 768)\n\n    positions = tf.range(start=0, limit=config[\"num_patches\"], delta=1)  # (256,)\n    pos_embedding = layers.Embedding(input_dim=config[\"num_patches\"], output_dim=config[\"hidden_units\"])(positions)  # (256, 768)\n    x = patch_embedding + pos_embedding  # (None, 256, 768)\n\n    #Transformer Encoder\n    skip_conn_indices = [3, 6, 9, 12]\n    skip_connections = []\n\n    for i in range(1, config[\"layers\"] + 1):\n        x = transformer_block(x, config)\n\n        if i in skip_conn_indices:\n            skip_connections.append(x)\n\n   \n    z3, z6, z9, z12 = skip_connections\n\n  \n    z0 = layers.Reshape((config[\"img_size\"], config[\"img_size\"], config[\"channels\"]))(inputs)\n\n    shape = (\n        config[\"img_size\"] // config[\"patch_size\"],\n        config[\"img_size\"] // config[\"patch_size\"],\n        config[\"hidden_units\"]\n    )\n    z3 = layers.Reshape(shape)(z3)\n    z6 = layers.Reshape(shape)(z6)\n    z9 = layers.Reshape(shape)(z9)\n    z12 = layers.Reshape(shape)(z12)\n\n   \n    total_upscale_factor = int(log2(config[\"patch_size\"]))\n    upscale = total_upscale_factor - 4\n\n    if upscale >= 2:  # Patch size 16 or greater\n        z3 = upconv_layer_block(z3, z3.shape[-1], strides=2 ** upscale)\n        z6 = upconv_layer_block(z6, z6.shape[-1], strides=2 ** upscale)\n        z9 = upconv_layer_block(z9, z9.shape[-1], strides=2 ** upscale)\n        z12 = upconv_layer_block(z12, z12.shape[-1], strides=2 ** upscale)\n\n    if upscale < 0:  # Patch size less than 16\n        p = 2 ** abs(upscale)\n        z3 = layers.MaxPool2D((p, p))(z3)\n        z6 = layers.MaxPool2D((p, p))(z6)\n        z9 = layers.MaxPool2D((p, p))(z9)\n        z12 = layers.MaxPool2D((p, p))(z12)\n\n    #Decoder 1\n    x = upconv_layer_block(z12, 128)\n\n    s = upconv_layer_block(z9, 128)\n    s = conv_layer_block(s, 128)\n\n    x = layers.Concatenate()([x, s])\n    x = conv_layer_block(x, 128)\n    x = conv_layer_block(x, 128)\n\n    # Decoder 2 \n    x = upconv_layer_block(x, 64)\n\n    s = upconv_layer_block(z6, 64)\n    s = conv_layer_block(s, 64)\n    s = upconv_layer_block(s, 64)\n    s = conv_layer_block(s, 64)\n\n    x = layers.Concatenate()([x, s])\n    x = conv_layer_block(x, 64)\n    x = conv_layer_block(x, 64)\n\n    #Decoder 3\n    x = upconv_layer_block(x, 32)\n\n    s = upconv_layer_block(z3, 32)\n    s = conv_layer_block(s, 32)\n    s = upconv_layer_block(s, 32)\n    s = conv_layer_block(s, 32)\n    s = upconv_layer_block(s, 32)\n    s = conv_layer_block(s, 32)\n\n    x = layers.Concatenate()([x, s])\n    x = conv_layer_block(x, 32)\n    x = conv_layer_block(x, 32)\n\n    #Decoder 4 \n    x = upconv_layer_block(x, 16)\n\n    s = conv_layer_block(z0, 16)\n    s = conv_layer_block(s, 16)\n\n    x = layers.Concatenate()([x, s])\n    x = conv_layer_block(x, 16)\n    x = conv_layer_block(x, 16)\n\n    #output\n    outputs = layers.Conv2D(1, kernel_size=1, padding=\"same\", activation=\"sigmoid\")(x)\n\n    return Model(inputs, outputs, name=\"Custom_UNETR_2D\")\n\nif __name__ == \"__main__\":\n    config = {}\n    config[\"img_size\"] = 512\n    config[\"layers\"] = 12\n    config[\"hidden_units\"] = 64\n    config[\"mlp_units\"] = 128\n    config[\"heads\"] = 6\n    config[\"dropout_rate\"] = 0.1\n    config[\"patch_size\"] = 512\n    config[\"num_patches\"] = (config[\"img_size\"] ** 2) // (config[\"patch_size\"] ** 2)\n    config[\"channels\"] = 3\n\n    model = build_custom_unet(config)\n    model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T07:58:53.564721Z","iopub.execute_input":"2024-07-25T07:58:53.565100Z","iopub.status.idle":"2024-07-25T07:58:57.659766Z","shell.execute_reply.started":"2024-07-25T07:58:53.565069Z","shell.execute_reply":"2024-07-25T07:58:57.657466Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model: \"Custom_UNETR_2D\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 1, 786432)]          0         []                            \n                                                                                                  \n dense (Dense)               (None, 1, 64)                5033171   ['input_1[0][0]']             \n                                                          2                                       \n                                                                                                  \n tf.__operators__.add (TFOp  (None, 1, 64)                0         ['dense[0][0]']               \n Lambda)                                                                                          \n                                                                                                  \n layer_normalization (Layer  (None, 1, 64)                128       ['tf.__operators__.add[0][0]']\n Normalization)                                                                                   \n                                                                                                  \n multi_head_attention (Mult  (None, 1, 64)                99520     ['layer_normalization[0][0]', \n iHeadAttention)                                                     'layer_normalization[0][0]'] \n                                                                                                  \n add (Add)                   (None, 1, 64)                0         ['multi_head_attention[0][0]',\n                                                                     'tf.__operators__.add[0][0]']\n                                                                                                  \n layer_normalization_1 (Lay  (None, 1, 64)                128       ['add[0][0]']                 \n erNormalization)                                                                                 \n                                                                                                  \n dense_1 (Dense)             (None, 1, 128)               8320      ['layer_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n dropout (Dropout)           (None, 1, 128)               0         ['dense_1[0][0]']             \n                                                                                                  \n dense_2 (Dense)             (None, 1, 64)                8256      ['dropout[0][0]']             \n                                                                                                  \n dropout_1 (Dropout)         (None, 1, 64)                0         ['dense_2[0][0]']             \n                                                                                                  \n add_1 (Add)                 (None, 1, 64)                0         ['dropout_1[0][0]',           \n                                                                     'add[0][0]']                 \n                                                                                                  \n layer_normalization_2 (Lay  (None, 1, 64)                128       ['add_1[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n multi_head_attention_1 (Mu  (None, 1, 64)                99520     ['layer_normalization_2[0][0]'\n ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]\n                                                                    ']                            \n                                                                                                  \n add_2 (Add)                 (None, 1, 64)                0         ['multi_head_attention_1[0][0]\n                                                                    ',                            \n                                                                     'add_1[0][0]']               \n                                                                                                  \n layer_normalization_3 (Lay  (None, 1, 64)                128       ['add_2[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n dense_3 (Dense)             (None, 1, 128)               8320      ['layer_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n dropout_2 (Dropout)         (None, 1, 128)               0         ['dense_3[0][0]']             \n                                                                                                  \n dense_4 (Dense)             (None, 1, 64)                8256      ['dropout_2[0][0]']           \n                                                                                                  \n dropout_3 (Dropout)         (None, 1, 64)                0         ['dense_4[0][0]']             \n                                                                                                  \n add_3 (Add)                 (None, 1, 64)                0         ['dropout_3[0][0]',           \n                                                                     'add_2[0][0]']               \n                                                                                                  \n layer_normalization_4 (Lay  (None, 1, 64)                128       ['add_3[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n multi_head_attention_2 (Mu  (None, 1, 64)                99520     ['layer_normalization_4[0][0]'\n ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n                                                                    ']                            \n                                                                                                  \n add_4 (Add)                 (None, 1, 64)                0         ['multi_head_attention_2[0][0]\n                                                                    ',                            \n                                                                     'add_3[0][0]']               \n                                                                                                  \n layer_normalization_5 (Lay  (None, 1, 64)                128       ['add_4[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n dense_5 (Dense)             (None, 1, 128)               8320      ['layer_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n dropout_4 (Dropout)         (None, 1, 128)               0         ['dense_5[0][0]']             \n                                                                                                  \n dense_6 (Dense)             (None, 1, 64)                8256      ['dropout_4[0][0]']           \n                                                                                                  \n dropout_5 (Dropout)         (None, 1, 64)                0         ['dense_6[0][0]']             \n                                                                                                  \n add_5 (Add)                 (None, 1, 64)                0         ['dropout_5[0][0]',           \n                                                                     'add_4[0][0]']               \n                                                                                                  \n layer_normalization_6 (Lay  (None, 1, 64)                128       ['add_5[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n multi_head_attention_3 (Mu  (None, 1, 64)                99520     ['layer_normalization_6[0][0]'\n ltiHeadAttention)                                                  , 'layer_normalization_6[0][0]\n                                                                    ']                            \n                                                                                                  \n add_6 (Add)                 (None, 1, 64)                0         ['multi_head_attention_3[0][0]\n                                                                    ',                            \n                                                                     'add_5[0][0]']               \n                                                                                                  \n layer_normalization_7 (Lay  (None, 1, 64)                128       ['add_6[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n dense_7 (Dense)             (None, 1, 128)               8320      ['layer_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n dropout_6 (Dropout)         (None, 1, 128)               0         ['dense_7[0][0]']             \n                                                                                                  \n dense_8 (Dense)             (None, 1, 64)                8256      ['dropout_6[0][0]']           \n                                                                                                  \n dropout_7 (Dropout)         (None, 1, 64)                0         ['dense_8[0][0]']             \n                                                                                                  \n add_7 (Add)                 (None, 1, 64)                0         ['dropout_7[0][0]',           \n                                                                     'add_6[0][0]']               \n                                                                                                  \n layer_normalization_8 (Lay  (None, 1, 64)                128       ['add_7[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n multi_head_attention_4 (Mu  (None, 1, 64)                99520     ['layer_normalization_8[0][0]'\n ltiHeadAttention)                                                  , 'layer_normalization_8[0][0]\n                                                                    ']                            \n                                                                                                  \n add_8 (Add)                 (None, 1, 64)                0         ['multi_head_attention_4[0][0]\n                                                                    ',                            \n                                                                     'add_7[0][0]']               \n                                                                                                  \n layer_normalization_9 (Lay  (None, 1, 64)                128       ['add_8[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n dense_9 (Dense)             (None, 1, 128)               8320      ['layer_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n dropout_8 (Dropout)         (None, 1, 128)               0         ['dense_9[0][0]']             \n                                                                                                  \n dense_10 (Dense)            (None, 1, 64)                8256      ['dropout_8[0][0]']           \n                                                                                                  \n dropout_9 (Dropout)         (None, 1, 64)                0         ['dense_10[0][0]']            \n                                                                                                  \n add_9 (Add)                 (None, 1, 64)                0         ['dropout_9[0][0]',           \n                                                                     'add_8[0][0]']               \n                                                                                                  \n layer_normalization_10 (La  (None, 1, 64)                128       ['add_9[0][0]']               \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_5 (Mu  (None, 1, 64)                99520     ['layer_normalization_10[0][0]\n ltiHeadAttention)                                                  ',                            \n                                                                     'layer_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n add_10 (Add)                (None, 1, 64)                0         ['multi_head_attention_5[0][0]\n                                                                    ',                            \n                                                                     'add_9[0][0]']               \n                                                                                                  \n layer_normalization_11 (La  (None, 1, 64)                128       ['add_10[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_11 (Dense)            (None, 1, 128)               8320      ['layer_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_10 (Dropout)        (None, 1, 128)               0         ['dense_11[0][0]']            \n                                                                                                  \n dense_12 (Dense)            (None, 1, 64)                8256      ['dropout_10[0][0]']          \n                                                                                                  \n dropout_11 (Dropout)        (None, 1, 64)                0         ['dense_12[0][0]']            \n                                                                                                  \n add_11 (Add)                (None, 1, 64)                0         ['dropout_11[0][0]',          \n                                                                     'add_10[0][0]']              \n                                                                                                  \n layer_normalization_12 (La  (None, 1, 64)                128       ['add_11[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_6 (Mu  (None, 1, 64)                99520     ['layer_normalization_12[0][0]\n ltiHeadAttention)                                                  ',                            \n                                                                     'layer_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n add_12 (Add)                (None, 1, 64)                0         ['multi_head_attention_6[0][0]\n                                                                    ',                            \n                                                                     'add_11[0][0]']              \n                                                                                                  \n layer_normalization_13 (La  (None, 1, 64)                128       ['add_12[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_13 (Dense)            (None, 1, 128)               8320      ['layer_normalization_13[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_12 (Dropout)        (None, 1, 128)               0         ['dense_13[0][0]']            \n                                                                                                  \n dense_14 (Dense)            (None, 1, 64)                8256      ['dropout_12[0][0]']          \n                                                                                                  \n dropout_13 (Dropout)        (None, 1, 64)                0         ['dense_14[0][0]']            \n                                                                                                  \n add_13 (Add)                (None, 1, 64)                0         ['dropout_13[0][0]',          \n                                                                     'add_12[0][0]']              \n                                                                                                  \n layer_normalization_14 (La  (None, 1, 64)                128       ['add_13[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_7 (Mu  (None, 1, 64)                99520     ['layer_normalization_14[0][0]\n ltiHeadAttention)                                                  ',                            \n                                                                     'layer_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n add_14 (Add)                (None, 1, 64)                0         ['multi_head_attention_7[0][0]\n                                                                    ',                            \n                                                                     'add_13[0][0]']              \n                                                                                                  \n layer_normalization_15 (La  (None, 1, 64)                128       ['add_14[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_15 (Dense)            (None, 1, 128)               8320      ['layer_normalization_15[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_14 (Dropout)        (None, 1, 128)               0         ['dense_15[0][0]']            \n                                                                                                  \n dense_16 (Dense)            (None, 1, 64)                8256      ['dropout_14[0][0]']          \n                                                                                                  \n dropout_15 (Dropout)        (None, 1, 64)                0         ['dense_16[0][0]']            \n                                                                                                  \n add_15 (Add)                (None, 1, 64)                0         ['dropout_15[0][0]',          \n                                                                     'add_14[0][0]']              \n                                                                                                  \n layer_normalization_16 (La  (None, 1, 64)                128       ['add_15[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_8 (Mu  (None, 1, 64)                99520     ['layer_normalization_16[0][0]\n ltiHeadAttention)                                                  ',                            \n                                                                     'layer_normalization_16[0][0]\n                                                                    ']                            \n                                                                                                  \n add_16 (Add)                (None, 1, 64)                0         ['multi_head_attention_8[0][0]\n                                                                    ',                            \n                                                                     'add_15[0][0]']              \n                                                                                                  \n layer_normalization_17 (La  (None, 1, 64)                128       ['add_16[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_17 (Dense)            (None, 1, 128)               8320      ['layer_normalization_17[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_16 (Dropout)        (None, 1, 128)               0         ['dense_17[0][0]']            \n                                                                                                  \n dense_18 (Dense)            (None, 1, 64)                8256      ['dropout_16[0][0]']          \n                                                                                                  \n dropout_17 (Dropout)        (None, 1, 64)                0         ['dense_18[0][0]']            \n                                                                                                  \n add_17 (Add)                (None, 1, 64)                0         ['dropout_17[0][0]',          \n                                                                     'add_16[0][0]']              \n                                                                                                  \n layer_normalization_18 (La  (None, 1, 64)                128       ['add_17[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_9 (Mu  (None, 1, 64)                99520     ['layer_normalization_18[0][0]\n ltiHeadAttention)                                                  ',                            \n                                                                     'layer_normalization_18[0][0]\n                                                                    ']                            \n                                                                                                  \n add_18 (Add)                (None, 1, 64)                0         ['multi_head_attention_9[0][0]\n                                                                    ',                            \n                                                                     'add_17[0][0]']              \n                                                                                                  \n layer_normalization_19 (La  (None, 1, 64)                128       ['add_18[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_19 (Dense)            (None, 1, 128)               8320      ['layer_normalization_19[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_18 (Dropout)        (None, 1, 128)               0         ['dense_19[0][0]']            \n                                                                                                  \n dense_20 (Dense)            (None, 1, 64)                8256      ['dropout_18[0][0]']          \n                                                                                                  \n dropout_19 (Dropout)        (None, 1, 64)                0         ['dense_20[0][0]']            \n                                                                                                  \n add_19 (Add)                (None, 1, 64)                0         ['dropout_19[0][0]',          \n                                                                     'add_18[0][0]']              \n                                                                                                  \n layer_normalization_20 (La  (None, 1, 64)                128       ['add_19[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_10 (M  (None, 1, 64)                99520     ['layer_normalization_20[0][0]\n ultiHeadAttention)                                                 ',                            \n                                                                     'layer_normalization_20[0][0]\n                                                                    ']                            \n                                                                                                  \n add_20 (Add)                (None, 1, 64)                0         ['multi_head_attention_10[0][0\n                                                                    ]',                           \n                                                                     'add_19[0][0]']              \n                                                                                                  \n layer_normalization_21 (La  (None, 1, 64)                128       ['add_20[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_21 (Dense)            (None, 1, 128)               8320      ['layer_normalization_21[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_20 (Dropout)        (None, 1, 128)               0         ['dense_21[0][0]']            \n                                                                                                  \n dense_22 (Dense)            (None, 1, 64)                8256      ['dropout_20[0][0]']          \n                                                                                                  \n dropout_21 (Dropout)        (None, 1, 64)                0         ['dense_22[0][0]']            \n                                                                                                  \n add_21 (Add)                (None, 1, 64)                0         ['dropout_21[0][0]',          \n                                                                     'add_20[0][0]']              \n                                                                                                  \n layer_normalization_22 (La  (None, 1, 64)                128       ['add_21[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n multi_head_attention_11 (M  (None, 1, 64)                99520     ['layer_normalization_22[0][0]\n ultiHeadAttention)                                                 ',                            \n                                                                     'layer_normalization_22[0][0]\n                                                                    ']                            \n                                                                                                  \n add_22 (Add)                (None, 1, 64)                0         ['multi_head_attention_11[0][0\n                                                                    ]',                           \n                                                                     'add_21[0][0]']              \n                                                                                                  \n layer_normalization_23 (La  (None, 1, 64)                128       ['add_22[0][0]']              \n yerNormalization)                                                                                \n                                                                                                  \n dense_23 (Dense)            (None, 1, 128)               8320      ['layer_normalization_23[0][0]\n                                                                    ']                            \n                                                                                                  \n dropout_22 (Dropout)        (None, 1, 128)               0         ['dense_23[0][0]']            \n                                                                                                  \n dense_24 (Dense)            (None, 1, 64)                8256      ['dropout_22[0][0]']          \n                                                                                                  \n reshape_3 (Reshape)         (None, 1, 1, 64)             0         ['add_17[0][0]']              \n                                                                                                  \n dropout_23 (Dropout)        (None, 1, 64)                0         ['dense_24[0][0]']            \n                                                                                                  \n conv2d_transpose_2 (Conv2D  (None, 32, 32, 64)           16448     ['reshape_3[0][0]']           \n Transpose)                                                                                       \n                                                                                                  \n add_23 (Add)                (None, 1, 64)                0         ['dropout_23[0][0]',          \n                                                                     'add_22[0][0]']              \n                                                                                                  \n conv2d_transpose_5 (Conv2D  (None, 64, 64, 128)          32896     ['conv2d_transpose_2[0][0]']  \n Transpose)                                                                                       \n                                                                                                  \n reshape_4 (Reshape)         (None, 1, 1, 64)             0         ['add_23[0][0]']              \n                                                                                                  \n conv2d (Conv2D)             (None, 64, 64, 128)          147584    ['conv2d_transpose_5[0][0]']  \n                                                                                                  \n conv2d_transpose_3 (Conv2D  (None, 32, 32, 64)           16448     ['reshape_4[0][0]']           \n Transpose)                                                                                       \n                                                                                                  \n batch_normalization (Batch  (None, 64, 64, 128)          512       ['conv2d[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n reshape_2 (Reshape)         (None, 1, 1, 64)             0         ['add_11[0][0]']              \n                                                                                                  \n conv2d_transpose_4 (Conv2D  (None, 64, 64, 128)          32896     ['conv2d_transpose_3[0][0]']  \n Transpose)                                                                                       \n                                                                                                  \n re_lu (ReLU)                (None, 64, 64, 128)          0         ['batch_normalization[0][0]'] \n                                                                                                  \n conv2d_transpose_1 (Conv2D  (None, 32, 32, 64)           16448     ['reshape_2[0][0]']           \n Transpose)                                                                                       \n                                                                                                  \n concatenate (Concatenate)   (None, 64, 64, 256)          0         ['conv2d_transpose_4[0][0]',  \n                                                                     're_lu[0][0]']               \n                                                                                                  \n conv2d_transpose_7 (Conv2D  (None, 64, 64, 64)           16448     ['conv2d_transpose_1[0][0]']  \n Transpose)                                                                                       \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 64, 64, 128)          295040    ['concatenate[0][0]']         \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d_transpose_7[0][0]']  \n                                                                                                  \n batch_normalization_1 (Bat  (None, 64, 64, 128)          512       ['conv2d_1[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_3 (Bat  (None, 64, 64, 64)           256       ['conv2d_3[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n reshape_1 (Reshape)         (None, 1, 1, 64)             0         ['add_5[0][0]']               \n                                                                                                  \n re_lu_1 (ReLU)              (None, 64, 64, 128)          0         ['batch_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n re_lu_3 (ReLU)              (None, 64, 64, 64)           0         ['batch_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_transpose (Conv2DTr  (None, 32, 32, 64)           16448     ['reshape_1[0][0]']           \n anspose)                                                                                         \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 64, 64, 128)          147584    ['re_lu_1[0][0]']             \n                                                                                                  \n conv2d_transpose_8 (Conv2D  (None, 128, 128, 64)         16448     ['re_lu_3[0][0]']             \n Transpose)                                                                                       \n                                                                                                  \n conv2d_transpose_10 (Conv2  (None, 64, 64, 32)           8224      ['conv2d_transpose[0][0]']    \n DTranspose)                                                                                      \n                                                                                                  \n batch_normalization_2 (Bat  (None, 64, 64, 128)          512       ['conv2d_2[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 128, 128, 64)         36928     ['conv2d_transpose_8[0][0]']  \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 64, 64, 32)           9248      ['conv2d_transpose_10[0][0]'] \n                                                                                                  \n re_lu_2 (ReLU)              (None, 64, 64, 128)          0         ['batch_normalization_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n batch_normalization_4 (Bat  (None, 128, 128, 64)         256       ['conv2d_4[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_7 (Bat  (None, 64, 64, 32)           128       ['conv2d_7[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n conv2d_transpose_6 (Conv2D  (None, 128, 128, 64)         32832     ['re_lu_2[0][0]']             \n Transpose)                                                                                       \n                                                                                                  \n re_lu_4 (ReLU)              (None, 128, 128, 64)         0         ['batch_normalization_4[0][0]'\n                                                                    ]                             \n                                                                                                  \n re_lu_7 (ReLU)              (None, 64, 64, 32)           0         ['batch_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n concatenate_1 (Concatenate  (None, 128, 128, 128)        0         ['conv2d_transpose_6[0][0]',  \n )                                                                   're_lu_4[0][0]']             \n                                                                                                  \n conv2d_transpose_11 (Conv2  (None, 128, 128, 32)         4128      ['re_lu_7[0][0]']             \n DTranspose)                                                                                      \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 128, 128, 64)         73792     ['concatenate_1[0][0]']       \n                                                                                                  \n conv2d_8 (Conv2D)           (None, 128, 128, 32)         9248      ['conv2d_transpose_11[0][0]'] \n                                                                                                  \n batch_normalization_5 (Bat  (None, 128, 128, 64)         256       ['conv2d_5[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_8 (Bat  (None, 128, 128, 32)         128       ['conv2d_8[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n re_lu_5 (ReLU)              (None, 128, 128, 64)         0         ['batch_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n re_lu_8 (ReLU)              (None, 128, 128, 32)         0         ['batch_normalization_8[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 128, 128, 64)         36928     ['re_lu_5[0][0]']             \n                                                                                                  \n conv2d_transpose_12 (Conv2  (None, 256, 256, 32)         4128      ['re_lu_8[0][0]']             \n DTranspose)                                                                                      \n                                                                                                  \n batch_normalization_6 (Bat  (None, 128, 128, 64)         256       ['conv2d_6[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n conv2d_9 (Conv2D)           (None, 256, 256, 32)         9248      ['conv2d_transpose_12[0][0]'] \n                                                                                                  \n re_lu_6 (ReLU)              (None, 128, 128, 64)         0         ['batch_normalization_6[0][0]'\n                                                                    ]                             \n                                                                                                  \n batch_normalization_9 (Bat  (None, 256, 256, 32)         128       ['conv2d_9[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n conv2d_transpose_9 (Conv2D  (None, 256, 256, 32)         8224      ['re_lu_6[0][0]']             \n Transpose)                                                                                       \n                                                                                                  \n re_lu_9 (ReLU)              (None, 256, 256, 32)         0         ['batch_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n concatenate_2 (Concatenate  (None, 256, 256, 64)         0         ['conv2d_transpose_9[0][0]',  \n )                                                                   're_lu_9[0][0]']             \n                                                                                                  \n conv2d_10 (Conv2D)          (None, 256, 256, 32)         18464     ['concatenate_2[0][0]']       \n                                                                                                  \n reshape (Reshape)           (None, 512, 512, 3)          0         ['input_1[0][0]']             \n                                                                                                  \n batch_normalization_10 (Ba  (None, 256, 256, 32)         128       ['conv2d_10[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 512, 512, 16)         448       ['reshape[0][0]']             \n                                                                                                  \n re_lu_10 (ReLU)             (None, 256, 256, 32)         0         ['batch_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_12 (Ba  (None, 512, 512, 16)         64        ['conv2d_12[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_11 (Conv2D)          (None, 256, 256, 32)         9248      ['re_lu_10[0][0]']            \n                                                                                                  \n re_lu_12 (ReLU)             (None, 512, 512, 16)         0         ['batch_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_11 (Ba  (None, 256, 256, 32)         128       ['conv2d_11[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 512, 512, 16)         2320      ['re_lu_12[0][0]']            \n                                                                                                  \n re_lu_11 (ReLU)             (None, 256, 256, 32)         0         ['batch_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_13 (Ba  (None, 512, 512, 16)         64        ['conv2d_13[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_transpose_13 (Conv2  (None, 512, 512, 16)         2064      ['re_lu_11[0][0]']            \n DTranspose)                                                                                      \n                                                                                                  \n re_lu_13 (ReLU)             (None, 512, 512, 16)         0         ['batch_normalization_13[0][0]\n                                                                    ']                            \n                                                                                                  \n concatenate_3 (Concatenate  (None, 512, 512, 32)         0         ['conv2d_transpose_13[0][0]', \n )                                                                   're_lu_13[0][0]']            \n                                                                                                  \n conv2d_14 (Conv2D)          (None, 512, 512, 16)         4624      ['concatenate_3[0][0]']       \n                                                                                                  \n batch_normalization_14 (Ba  (None, 512, 512, 16)         64        ['conv2d_14[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_14 (ReLU)             (None, 512, 512, 16)         0         ['batch_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_15 (Conv2D)          (None, 512, 512, 16)         2320      ['re_lu_14[0][0]']            \n                                                                                                  \n batch_normalization_15 (Ba  (None, 512, 512, 16)         64        ['conv2d_15[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n re_lu_15 (ReLU)             (None, 512, 512, 16)         0         ['batch_normalization_15[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_16 (Conv2D)          (None, 512, 512, 1)          17        ['re_lu_15[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 52795441 (201.40 MB)\nTrainable params: 52793713 (201.39 MB)\nNon-trainable params: 1728 (6.75 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nimport numpy as np\nimport cv2\nfrom glob import glob\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, Callback\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom sklearn.model_selection import train_test_split\nfrom patchify import patchify\n\n#configuration\ncf = {}\ncf[\"img_size\"] = 256\ncf[\"channels\"] = 3\ncf[\"layers\"] = 12\ncf[\"hidden_units\"] = 128\ncf[\"mlp_units\"] = 32\ncf[\"heads\"] = 6\ncf[\"dropout_rate\"] = 0.1\ncf[\"patch_size\"] = 16\ncf[\"num_patches\"] = (cf[\"img_size\"]**2)//(cf[\"patch_size\"]**2)\ncf[\"flat_patches_shape\"] = (\n    cf[\"num_patches\"],\n    cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"channels\"]\n)\n\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ndef load_dataset(path, split=0.1):\n\n    X = sorted(glob(os.path.join(path, \"train\", \"*_sat.jpg\")))\n    Y = sorted(glob(os.path.join(path, \"train\", \"*_mask.png\")))\n\n    split_size = int(len(X) * split)\n\n    train_x, valid_x = train_test_split(X, test_size=split_size, random_state=42)\n    train_y, valid_y = train_test_split(Y, test_size=split_size, random_state=42)\n\n    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n\ndef read_image(path):\n    path = path.decode()\n    image = cv2.imread(path, cv2.IMREAD_COLOR)\n    image = cv2.resize(image, (cf[\"img_size\"], cf[\"img_size\"]))\n    image = image / 255.0\n\n\n    patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"channels\"])\n    patches = patchify(image, patch_shape, cf[\"patch_size\"])\n    patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n    patches = patches.astype(np.float32)\n\n    return patches\n\ndef read_mask(path):\n    path = path.decode()\n    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (cf[\"img_size\"], cf[\"img_size\"]))\n    mask = mask / 255.0\n    mask = mask.astype(np.float32)\n    mask = np.expand_dims(mask, axis=-1)\n    return mask\n\ndef tf_parse(x, y):\n    def _parse(x, y):\n        x = read_image(x)\n        y = read_mask(y)\n        return x, y\n\n    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n    x.set_shape(cf[\"flat_patches_shape\"])\n    y.set_shape([cf[\"img_size\"], cf[\"img_size\"], 1])\n    return x, y\n\ndef tf_dataset(X, Y, batch=2):\n    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n    ds = ds.map(tf_parse).batch(batch).prefetch(10)\n    return ds\n\nclass SaveModelEveryN(Callback):\n    def __init__(self, save_path, n_epochs):\n        super(SaveModelEveryN, self).__init__()\n        self.save_path = save_path\n        self.n_epochs = n_epochs\n\n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.n_epochs == 0:\n            save_path = os.path.join(self.save_path, f\"model_epoch_{epoch+1}.h5\")\n            self.model.save(save_path)\n            print(f\"\\nModel saved to {save_path}\")\n\nif __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n    \n    create_dir(\"files\")\n\n    # Hyperparameters\n    batch_size = 8\n    lr = 0.1\n    num_epochs = 500\n    model_path = os.path.join(\"files\", \"model_best.h5\")\n    csv_path = os.path.join(\"files\", \"log.csv\")\n    save_dir = \"files\"\n\n    dataset_path = \"/kaggle/input/deepglobe-road-extraction-dataset\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n\n    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n\n\n    model = build_custom_unet(cf)\n    #model.load_weights(\"/kaggle/input/road-extraction-transformer-based-unet/keras/40-epoch/1/model_epoch_40.h5\")\n    model.compile(loss=dice_loss, optimizer=SGD(lr), metrics=['accuracy'])\n    # model.summary()\n\n    callbacks = [\n        ModelCheckpoint(model_path, verbose=1, save_best_only=True, monitor='val_loss', mode='min'),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n        CSVLogger(csv_path),\n        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n        SaveModelEveryN(save_path=save_dir, n_epochs=10)\n    ]\n\n    model.fit(\n        train_dataset,\n        epochs=num_epochs,\n        validation_data=valid_dataset,\n        callbacks=callbacks\n    )","metadata":{"execution":{"iopub.status.busy":"2024-07-25T07:58:57.668464Z","iopub.execute_input":"2024-07-25T07:58:57.668834Z","iopub.status.idle":"2024-07-25T07:59:08.302492Z","shell.execute_reply.started":"2024-07-25T07:58:57.668805Z","shell.execute_reply":"2024-07-25T07:59:08.299847Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/500\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 135\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# model.summary()\u001b[39;00m\n\u001b[1;32m    127\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    128\u001b[0m     ModelCheckpoint(model_path, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    129\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m     SaveModelEveryN(save_path\u001b[38;5;241m=\u001b[39msave_dir, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    133\u001b[0m ]\n\u001b[0;32m--> 135\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 888\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    891\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n","File \u001b[0;32m/tmp/__autograph_generated_file71_mby8s.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1381\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1384\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m     outputs,\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1388\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1389\u001b[0m )\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4068\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1373\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1373\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1154\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:544\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03mThis method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m  None\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    543\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_gradients(loss, var_list, tape)\n\u001b[0;32m--> 544\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:1223\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1222\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:638\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(scope_name):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;66;03m# Lift variable creation to init scope to avoid environment\u001b[39;00m\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;66;03m# issues.\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m optimizer_utils\u001b[38;5;241m.\u001b[39mfilter_empty_gradients(\n\u001b[1;32m    640\u001b[0m         grads_and_vars\n\u001b[1;32m    641\u001b[0m     )\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(grads_and_vars)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;66;03m# Check again after filtering gradients.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/sgd.py:149\u001b[0m, in \u001b[0;36mSGD.build\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentums \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m var_list:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentums\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 149\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_variable_from_reference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_variable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_built \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:1125\u001b[0m, in \u001b[0;36mOptimizer.add_variable_from_reference\u001b[0;34m(self, model_variable, variable_name, shape, initial_value)\u001b[0m\n\u001b[1;32m   1123\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mcolocate_vars_with(model_variable):\n\u001b[0;32m-> 1125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_variable_from_reference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_value\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:513\u001b[0m, in \u001b[0;36m_BaseOptimizer.add_variable_from_reference\u001b[0;34m(self, model_variable, variable_name, shape, initial_value)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m         initial_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros(shape, dtype\u001b[38;5;241m=\u001b[39mmodel_variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 513\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvariable_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_variable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shared_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_variable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables\u001b[38;5;241m.\u001b[39mappend(variable)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m variable\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/variables.py:195\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    194\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_variable_call\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_call):\n\u001b[0;32m--> 195\u001b[0m     variable_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m variable_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m variable_call\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/variables.py:1227\u001b[0m, in \u001b[0;36mVariable._variable_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape, experimental_enable_variable_lifting, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggregation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1226\u001b[0m   aggregation \u001b[38;5;241m=\u001b[39m VariableAggregation\u001b[38;5;241m.\u001b[39mNONE\n\u001b[0;32m-> 1227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprevious_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/variables.py:56\u001b[0m, in \u001b[0;36m_make_getter.<locals>.getter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetter\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 56\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaptured_getter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptured_previous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3984\u001b[0m, in \u001b[0;36m_DefaultDistributionContext.__init__.<locals>.creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3982\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreator\u001b[39m(next_creator, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3983\u001b[0m   _require_strategy_scope_strategy(strategy)\n\u001b[0;32m-> 3984\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnext_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/variables.py:56\u001b[0m, in \u001b[0;36m_make_getter.<locals>.getter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetter\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 56\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaptured_getter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptured_previous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3984\u001b[0m, in \u001b[0;36m_DefaultDistributionContext.__init__.<locals>.creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3982\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreator\u001b[39m(next_creator, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3983\u001b[0m   _require_strategy_scope_strategy(strategy)\n\u001b[0;32m-> 3984\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnext_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/variables.py:56\u001b[0m, in \u001b[0;36m_make_getter.<locals>.getter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetter\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 56\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaptured_getter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptured_previous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3984\u001b[0m, in \u001b[0;36m_DefaultDistributionContext.__init__.<locals>.creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3982\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreator\u001b[39m(next_creator, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3983\u001b[0m   _require_strategy_scope_strategy(strategy)\n\u001b[0;32m-> 3984\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnext_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/variables.py:56\u001b[0m, in \u001b[0;36m_make_getter.<locals>.getter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetter\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 56\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaptured_getter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptured_previous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:683\u001b[0m, in \u001b[0;36mFunction._initialize.<locals>.variable_capturing_scope\u001b[0;34m(next_creator, **kwds)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m enable_variable_lifting:\n\u001b[1;32m    682\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m next_creator(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m--> 683\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mUnliftedInitializerVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m created_variables\u001b[38;5;241m.\u001b[39mappend(weakref\u001b[38;5;241m.\u001b[39mref(v))\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/variables.py:198\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m variable_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m variable_call\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mVariableMetaclass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:321\u001b[0m, in \u001b[0;36mUnliftedInitializerVariable.__init__\u001b[0;34m(self, initial_value, trainable, caching_device, name, dtype, constraint, add_initializers_to, synchronization, aggregation, shape, **unused_kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     shape \u001b[38;5;241m=\u001b[39m initial_value\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# Use the constructor for UninitializedVariable to start. Outside the name\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# scope so we don't double up the prefix.\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_handle_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munused_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(scope_name):\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_graph_mode:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:2294\u001b[0m, in \u001b[0;36mUninitializedVariable.__init__\u001b[0;34m(self, trainable, caching_device, name, shape, dtype, constraint, synchronization, aggregation, extra_handle_data, distribute_strategy, **unused_kwargs)\u001b[0m\n\u001b[1;32m   2292\u001b[0m   unique_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (handle_name, ops\u001b[38;5;241m.\u001b[39muid())\n\u001b[1;32m   2293\u001b[0m   shared_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Never shared\u001b[39;00m\n\u001b[0;32m-> 2294\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[43m_variable_handle_from_shape_and_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshared_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshared_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_in_graph_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_handle_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2301\u001b[0m handle\u001b[38;5;241m.\u001b[39m_parent_trackable \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   2302\u001b[0m handle\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m handle_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:171\u001b[0m, in \u001b[0;36m_variable_handle_from_shape_and_dtype\u001b[0;34m(shape, dtype, shared_name, name, graph_mode, initial_value)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInternalError(\n\u001b[1;32m    165\u001b[0m         node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    166\u001b[0m         op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    167\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing an explicit shared_name is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot allowed when executing eagerly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m   shared_name \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39manonymous_name()\n\u001b[0;32m--> 171\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_handle_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshared_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshared_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m   initial_value \u001b[38;5;241m=\u001b[39m handle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:1267\u001b[0m, in \u001b[0;36mvar_handle_op\u001b[0;34m(dtype, shape, container, shared_name, debug_name, allowed_devices, name)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   1266\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1267\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVarHandleOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshared_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshared_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebug_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallowed_devices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_devices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   1272\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport pandas as pd\nfrom glob import glob\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\ncf = {}\ncf[\"img_size\"] = 256\ncf[\"channels\"] = 3\n\nif __name__ == \"__main__\":\n   \n    np.random.seed(42)\n    tf.random.set_seed(42)\n   \n    def create_dir(path):\n        if not os.path.exists(path):\n            os.makedirs(path)\n\n    create_dir(f\"results_UNET_TR_v3\")\n\n    model_path = r\"/kaggle/input/custom-transformer-based-unet/keras/default/1/UNET_Transformer_final.h5\"\n    model = tf.keras.models.load_model(model_path, custom_objects={\"dice_loss\": dice_loss})\n\n    dataset_path = r\"/kaggle/input/deepglobe-road-extraction-dataset\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n\n    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n        name = x.split(\"/\")[-1]\n        \n        img = plt.imread(x)\n        mask=plt.imread(y)\n        img = cv2.resize(img, (256, 256))\n        mask = cv2.resize(mask, (256, 256))\n        \n        if img.shape[-1] == 4:  \n            img = img[..., :3]  #remving the alpha chanel\n        elif img.shape[-1] == 1:  # If image is grayscale\n            img = np.repeat(img, 3, axis=-1)  # Converting to rgb\n\n        # Ensure the mask has 1 channel\n        if mask.ndim == 3 and mask.shape[-1] == 3:\n            mask = mask[..., 0]  \n        img = np.expand_dims(img, axis=0)  \n        mask = np.expand_dims(mask, axis=-1) \n\n        print(f\"Image shape: {img.shape}, Mask shape: {mask.shape}\")\n  \n        frameObj={}\n        frameObj['img']=img\n        frameObj['mask']=mask[:,:,0]\n       \n        img = frameObj['img']\n        mask = frameObj['mask']\n        imgProc = img\n        \n    \n        plt.figure(figsize=(10, 10))\n    \n        plt.subplot(1, 3, 1)\n        plt.imshow(img[0])\n        plt.title('Aerial image')\n        \n        plt.subplot(1, 3, 3)\n        plt.imshow(mask[:, :, 0] if mask.ndim == 3 else mask, cmap='gray')\n        plt.title('Actual Routes')\n\n        predictions = model.predict(img)\n        predictions = (predictions > 0.1).astype(np.float32)  # Thresholding to get binary mask\n        plt.subplot(1, 3, 2)\n        plt.imshow(predictions[0, :, :, 0], cmap='gray')\n        plt.title('Predicted Routes')\n#         plt.show()\n        \n        plt.savefig(f'results_UNET_TR_v3/{name}.png')\n        plt.close() \n\n      \n \n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T08:27:29.045778Z","iopub.execute_input":"2024-07-25T08:27:29.046155Z","iopub.status.idle":"2024-07-25T08:34:29.628748Z","shell.execute_reply.started":"2024-07-25T08:27:29.046127Z","shell.execute_reply":"2024-07-25T08:34:29.627703Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"  0%|          | 0/622 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 1s 608ms/step\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/622 [00:01<12:00,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 113ms/step\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 2/622 [00:01<08:40,  1.19it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 3/622 [00:02<07:29,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 4/622 [00:02<06:54,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 115ms/step\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 5/622 [00:03<06:48,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 6/622 [00:04<06:32,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 7/622 [00:04<06:22,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 8/622 [00:05<06:16,  1.63it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 9/622 [00:06<06:20,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 10/622 [00:06<06:14,  1.64it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 11/622 [00:07<06:16,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 12/622 [00:07<06:16,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 13/622 [00:08<06:19,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 14/622 [00:09<06:21,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 15/622 [00:09<06:12,  1.63it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 16/622 [00:10<06:07,  1.65it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 17/622 [00:10<06:03,  1.66it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 18/622 [00:11<06:02,  1.67it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 19/622 [00:12<06:00,  1.67it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 20/622 [00:12<06:07,  1.64it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 21/622 [00:13<06:14,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"  4%|▎         | 22/622 [00:13<06:14,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  4%|▎         | 23/622 [00:14<06:08,  1.63it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 24/622 [00:15<06:12,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 25/622 [00:15<06:15,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 26/622 [00:16<06:16,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 27/622 [00:17<08:26,  1.17it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 109ms/step\n","output_type":"stream"},{"name":"stderr","text":"  5%|▍         | 28/622 [00:18<07:45,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 109ms/step\n","output_type":"stream"},{"name":"stderr","text":"  5%|▍         | 29/622 [00:19<07:22,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":"  5%|▍         | 30/622 [00:19<06:56,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":"  5%|▍         | 31/622 [00:20<06:40,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 108ms/step\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 32/622 [00:21<06:35,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 33/622 [00:21<06:34,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 34/622 [00:22<06:30,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 109ms/step\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 35/622 [00:22<06:27,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 113ms/step\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 36/622 [00:23<06:30,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 37/622 [00:24<06:25,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 38/622 [00:24<06:13,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 108ms/step\n","output_type":"stream"},{"name":"stderr","text":"  6%|▋         | 39/622 [00:25<06:08,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":"  6%|▋         | 40/622 [00:26<06:04,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 110ms/step\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 41/622 [00:26<06:09,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 42/622 [00:27<06:10,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 43/622 [00:28<06:05,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 44/622 [00:28<06:11,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 45/622 [00:29<06:05,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 46/622 [00:29<06:04,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 47/622 [00:30<05:59,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 48/622 [00:31<05:56,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 49/622 [00:31<06:01,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 139ms/step\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 50/622 [00:32<06:17,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 127ms/step\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 51/622 [00:33<06:28,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 52/622 [00:33<06:23,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 53/622 [00:34<06:19,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 54/622 [00:35<06:19,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 55/622 [00:35<06:20,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 56/622 [00:36<06:19,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 57/622 [00:37<06:13,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 58/622 [00:37<06:10,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 59/622 [00:38<06:12,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 10%|▉         | 60/622 [00:39<06:10,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 10%|▉         | 61/622 [00:39<06:11,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 10%|▉         | 62/622 [00:40<06:02,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 63/622 [00:41<05:57,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 64/622 [00:41<05:52,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 65/622 [00:42<05:47,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 66/622 [00:42<05:43,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 109ms/step\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 67/622 [00:43<05:48,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 68/622 [00:44<05:42,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 69/622 [00:44<05:41,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 11%|█▏        | 70/622 [00:45<05:40,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 11%|█▏        | 71/622 [00:46<05:40,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 72/622 [00:47<07:55,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 73/622 [00:48<07:25,  1.23it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 74/622 [00:48<07:02,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 75/622 [00:49<06:50,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 76/622 [00:50<06:42,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 77/622 [00:50<06:35,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 78/622 [00:51<06:19,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 79/622 [00:52<06:14,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 80/622 [00:52<06:07,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 111ms/step\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 81/622 [00:53<06:08,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 82/622 [00:54<06:02,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 83/622 [00:54<05:58,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▎        | 84/622 [00:55<05:58,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▎        | 85/622 [00:56<06:04,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 86/622 [00:56<06:01,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 87/622 [00:57<05:56,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 88/622 [00:58<05:53,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 89/622 [00:58<05:47,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 90/622 [00:59<05:44,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▍        | 91/622 [01:00<05:46,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▍        | 92/622 [01:00<05:49,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▍        | 93/622 [01:01<05:48,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 94/622 [01:02<05:46,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 95/622 [01:02<05:44,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 96/622 [01:03<05:49,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 127ms/step\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 97/622 [01:04<05:54,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 126ms/step\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 98/622 [01:04<05:54,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 99/622 [01:05<05:51,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 100/622 [01:06<05:55,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 101/622 [01:06<05:49,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▋        | 102/622 [01:07<05:45,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 103/622 [01:08<05:45,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 104/622 [01:08<05:49,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 105/622 [01:09<05:49,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 106/622 [01:10<05:46,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 107/622 [01:10<05:44,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 108/622 [01:11<05:41,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 109/622 [01:12<05:37,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 110/622 [01:12<05:36,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 111/622 [01:13<05:40,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 112/622 [01:14<05:42,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 113/622 [01:14<05:39,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 114/622 [01:15<05:31,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 115/622 [01:16<05:24,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▊        | 116/622 [01:16<05:22,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 117/622 [01:17<05:17,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 118/622 [01:18<05:18,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 119/622 [01:18<05:23,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 120/622 [01:19<05:26,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 121/622 [01:19<05:26,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 20%|█▉        | 122/622 [01:20<05:20,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 20%|█▉        | 123/622 [01:21<05:14,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 20%|█▉        | 124/622 [01:21<05:12,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 125/622 [01:22<05:11,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 126/622 [01:23<05:10,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 140ms/step\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 127/622 [01:23<05:15,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 128/622 [01:25<07:42,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 129/622 [01:26<07:05,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 130/622 [01:26<06:40,  1.23it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 131/622 [01:27<06:21,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 132/622 [01:28<06:08,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 21%|██▏       | 133/622 [01:28<05:57,  1.37it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 134/622 [01:29<05:53,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 135/622 [01:30<05:48,  1.40it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 136/622 [01:30<05:35,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 137/622 [01:31<05:23,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 138/622 [01:32<05:16,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 139/622 [01:32<05:15,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 140/622 [01:33<05:18,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 141/622 [01:34<05:18,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 142/622 [01:34<05:09,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 143/622 [01:35<05:11,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 141ms/step\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 144/622 [01:36<05:20,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 132ms/step\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 145/622 [01:36<05:25,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 146/622 [01:37<05:19,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▎       | 147/622 [01:38<05:17,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 148/622 [01:38<05:19,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 149/622 [01:39<05:21,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 150/622 [01:40<05:20,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 151/622 [01:40<05:23,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 152/622 [01:41<05:23,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▍       | 153/622 [01:42<05:18,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▍       | 154/622 [01:42<05:16,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▍       | 155/622 [01:43<05:17,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 156/622 [01:44<05:16,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 157/622 [01:44<05:19,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 158/622 [01:45<05:20,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 159/622 [01:46<05:18,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 160/622 [01:47<05:16,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 161/622 [01:47<05:13,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 162/622 [01:48<05:08,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 163/622 [01:48<05:01,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▋       | 164/622 [01:49<04:57,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 165/622 [01:50<04:55,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 166/622 [01:50<04:56,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 167/622 [01:51<04:52,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 168/622 [01:52<04:45,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 169/622 [01:52<04:42,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 170/622 [01:53<04:44,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 171/622 [01:53<04:41,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 172/622 [01:54<04:38,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 173/622 [01:55<04:37,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 174/622 [01:55<04:40,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 175/622 [01:56<04:46,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 176/622 [01:57<04:42,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 177/622 [01:57<04:41,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▊       | 178/622 [01:58<04:43,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 179/622 [01:59<04:44,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 180/622 [01:59<04:45,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 181/622 [02:00<04:41,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 182/622 [02:00<04:41,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 183/622 [02:01<04:40,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 30%|██▉       | 184/622 [02:02<04:38,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 30%|██▉       | 185/622 [02:02<04:38,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 108ms/step\n","output_type":"stream"},{"name":"stderr","text":" 30%|██▉       | 186/622 [02:03<04:51,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 187/622 [02:04<04:52,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 188/622 [02:05<04:52,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 189/622 [02:05<04:50,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 31%|███       | 190/622 [02:06<04:50,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 31%|███       | 191/622 [02:07<04:53,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 125ms/step\n","output_type":"stream"},{"name":"stderr","text":" 31%|███       | 192/622 [02:07<04:57,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 131ms/step\n","output_type":"stream"},{"name":"stderr","text":" 31%|███       | 193/622 [02:08<04:59,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 31%|███       | 194/622 [02:09<04:46,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 31%|███▏      | 195/622 [02:09<04:39,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 196/622 [02:10<04:34,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 197/622 [02:12<07:04,  1.00it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 198/622 [02:12<06:27,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 199/622 [02:13<05:59,  1.18it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 200/622 [02:14<05:36,  1.26it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 201/622 [02:14<05:15,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 202/622 [02:15<05:04,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 203/622 [02:16<04:55,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 204/622 [02:16<04:54,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 205/622 [02:17<04:54,  1.41it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 206/622 [02:18<04:42,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 207/622 [02:18<04:41,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 208/622 [02:19<04:36,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▎      | 209/622 [02:20<04:37,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 210/622 [02:20<04:41,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 211/622 [02:21<04:36,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 212/622 [02:22<04:34,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 213/622 [02:22<04:33,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 111ms/step\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 214/622 [02:23<04:35,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▍      | 215/622 [02:24<04:34,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▍      | 216/622 [02:24<04:32,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▍      | 217/622 [02:25<04:23,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 218/622 [02:26<04:18,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 219/622 [02:26<04:12,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 220/622 [02:27<04:09,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 221/622 [02:27<04:10,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 222/622 [02:28<04:09,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 223/622 [02:29<04:13,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 224/622 [02:29<04:14,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 225/622 [02:30<04:12,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▋      | 226/622 [02:31<04:12,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▋      | 227/622 [02:31<04:11,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 228/622 [02:32<04:09,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 108ms/step\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 229/622 [02:33<04:13,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 114ms/step\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 230/622 [02:33<04:20,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 231/622 [02:34<04:20,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 232/622 [02:35<04:20,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 233/622 [02:35<04:21,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 234/622 [02:36<04:17,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 235/622 [02:37<04:16,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 236/622 [02:37<04:18,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 237/622 [02:38<04:17,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 137ms/step\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 238/622 [02:39<04:25,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 127ms/step\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 239/622 [02:39<04:28,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▊      | 240/622 [02:40<04:24,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▊      | 241/622 [02:41<04:23,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 242/622 [02:42<04:20,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 243/622 [02:42<04:16,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 244/622 [02:43<04:15,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 245/622 [02:44<04:11,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 40%|███▉      | 246/622 [02:44<04:13,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 40%|███▉      | 247/622 [02:45<04:12,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 40%|███▉      | 248/622 [02:46<04:08,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 249/622 [02:46<04:06,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 250/622 [02:47<04:12,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 251/622 [02:47<04:05,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 252/622 [02:48<04:03,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 253/622 [02:49<03:57,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 254/622 [02:49<03:55,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 255/622 [02:50<03:57,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 256/622 [02:51<03:57,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 41%|████▏     | 257/622 [02:51<04:01,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 41%|████▏     | 258/622 [02:52<04:02,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 259/622 [02:53<03:57,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 260/622 [02:53<03:55,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 261/622 [02:54<03:56,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 262/622 [02:55<03:56,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 263/622 [02:55<03:55,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 264/622 [02:56<03:53,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 265/622 [02:57<03:51,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 266/622 [02:57<03:47,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 267/622 [02:58<03:49,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 268/622 [02:59<03:48,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 269/622 [02:59<03:49,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 270/622 [03:00<03:51,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▎     | 271/622 [03:01<03:51,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▎     | 272/622 [03:01<03:52,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 273/622 [03:02<03:45,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 274/622 [03:02<03:42,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 275/622 [03:03<03:44,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 110ms/step\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 276/622 [03:04<03:46,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▍     | 277/622 [03:04<03:47,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▍     | 278/622 [03:05<03:49,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▍     | 279/622 [03:06<03:50,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 280/622 [03:06<03:49,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 281/622 [03:07<03:45,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 282/622 [03:09<06:11,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 283/622 [03:10<05:23,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 133ms/step\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▌     | 284/622 [03:11<05:00,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 129ms/step\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▌     | 285/622 [03:11<04:42,  1.19it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▌     | 286/622 [03:12<04:20,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▌     | 287/622 [03:13<04:07,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 138ms/step\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▋     | 288/622 [03:13<03:59,  1.39it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▋     | 289/622 [03:14<03:50,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 290/622 [03:15<03:46,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 291/622 [03:15<03:42,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 292/622 [03:16<03:38,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 293/622 [03:16<03:33,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 294/622 [03:17<03:30,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 295/622 [03:18<03:25,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 296/622 [03:18<03:23,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 108ms/step\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 297/622 [03:19<03:21,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 298/622 [03:20<03:24,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 299/622 [03:20<03:25,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 110ms/step\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 300/622 [03:21<03:29,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 301/622 [03:22<03:31,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▊     | 302/622 [03:22<03:30,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▊     | 303/622 [03:23<03:33,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 304/622 [03:24<03:35,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 305/622 [03:24<03:35,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 306/622 [03:25<03:36,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 307/622 [03:26<03:29,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 50%|████▉     | 308/622 [03:26<03:24,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 50%|████▉     | 309/622 [03:27<03:20,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 50%|████▉     | 310/622 [03:28<03:26,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 311/622 [03:28<03:24,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 312/622 [03:29<03:23,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 313/622 [03:30<03:21,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 314/622 [03:30<03:22,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 315/622 [03:31<03:21,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 316/622 [03:31<03:19,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 317/622 [03:32<03:18,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 318/622 [03:33<03:18,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████▏    | 319/622 [03:33<03:20,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████▏    | 320/622 [03:34<03:18,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 321/622 [03:35<03:17,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 322/622 [03:35<03:16,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 323/622 [03:36<03:15,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 324/622 [03:37<03:15,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 325/622 [03:37<03:14,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 326/622 [03:38<03:13,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 327/622 [03:39<03:10,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 328/622 [03:39<03:15,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 329/622 [03:40<03:16,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 330/622 [03:41<03:16,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 331/622 [03:41<03:15,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 124ms/step\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 332/622 [03:42<03:20,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 129ms/step\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▎    | 333/622 [03:43<03:25,  1.41it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▎    | 334/622 [03:44<03:21,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 335/622 [03:44<03:19,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 336/622 [03:45<03:15,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 337/622 [03:46<03:09,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 338/622 [03:46<03:03,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▍    | 339/622 [03:47<03:04,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▍    | 340/622 [03:47<03:03,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▍    | 341/622 [03:48<03:03,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▍    | 342/622 [03:49<03:03,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 343/622 [03:49<03:03,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 344/622 [03:50<02:59,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 345/622 [03:51<02:55,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 346/622 [03:51<02:52,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 347/622 [03:52<02:54,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 348/622 [03:53<02:51,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 111ms/step\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 349/622 [03:53<02:54,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▋    | 350/622 [03:54<02:53,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▋    | 351/622 [03:54<02:51,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 352/622 [03:55<02:48,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 353/622 [03:56<02:48,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 354/622 [03:56<02:46,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 355/622 [03:57<02:48,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 356/622 [03:58<02:45,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 357/622 [03:58<02:48,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 358/622 [03:59<02:57,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 359/622 [04:00<02:58,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 360/622 [04:00<03:04,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 361/622 [04:01<03:02,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 362/622 [04:02<03:01,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 363/622 [04:02<02:57,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▊    | 364/622 [04:03<02:57,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▊    | 365/622 [04:04<02:54,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 366/622 [04:04<02:50,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 367/622 [04:05<02:47,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 368/622 [04:06<02:44,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 369/622 [04:06<02:41,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 370/622 [04:07<02:40,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 60%|█████▉    | 371/622 [04:08<02:42,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 60%|█████▉    | 372/622 [04:08<02:43,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 60%|█████▉    | 373/622 [04:09<02:42,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 374/622 [04:10<02:41,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 375/622 [04:10<02:40,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 376/622 [04:11<02:42,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 377/622 [04:12<02:40,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 378/622 [04:12<02:41,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 379/622 [04:13<02:39,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 380/622 [04:14<02:41,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 130ms/step\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████▏   | 381/622 [04:14<02:43,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 114ms/step\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████▏   | 382/622 [04:15<02:41,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 383/622 [04:16<02:41,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 384/622 [04:16<02:38,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 385/622 [04:17<02:38,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 386/622 [04:18<02:41,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 387/622 [04:18<02:38,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 388/622 [04:21<04:42,  1.21s/it]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 389/622 [04:21<04:01,  1.04s/it]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 390/622 [04:22<03:34,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 391/622 [04:23<03:14,  1.19it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 392/622 [04:23<03:00,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 393/622 [04:24<02:53,  1.32it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 394/622 [04:25<02:47,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▎   | 395/622 [04:25<02:41,  1.40it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▎   | 396/622 [04:26<02:39,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 397/622 [04:27<02:37,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 398/622 [04:27<02:36,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 399/622 [04:28<02:35,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 400/622 [04:29<02:31,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 401/622 [04:29<02:28,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▍   | 402/622 [04:30<02:23,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▍   | 403/622 [04:31<02:19,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▍   | 404/622 [04:31<02:19,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 405/622 [04:32<02:18,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 406/622 [04:33<02:18,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 132ms/step\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 407/622 [04:33<02:18,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 408/622 [04:34<02:16,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 409/622 [04:35<02:18,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 410/622 [04:35<02:17,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 411/622 [04:36<02:19,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 412/622 [04:37<02:20,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▋   | 413/622 [04:37<02:17,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 414/622 [04:38<02:18,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 415/622 [04:39<02:15,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 416/622 [04:39<02:19,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 417/622 [04:40<02:15,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 418/622 [04:41<02:12,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 108ms/step\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 419/622 [04:41<02:12,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 420/622 [04:42<02:09,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 421/622 [04:42<02:10,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 422/622 [04:43<02:12,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 423/622 [04:44<02:12,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 424/622 [04:44<02:12,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 425/622 [04:45<02:12,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 129ms/step\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 426/622 [04:46<02:13,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 120ms/step\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▊   | 427/622 [04:47<02:15,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▉   | 428/622 [04:47<02:14,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▉   | 429/622 [04:48<02:13,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▉   | 430/622 [04:49<02:10,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▉   | 431/622 [04:49<02:07,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▉   | 432/622 [04:50<02:06,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 70%|██████▉   | 433/622 [04:51<02:05,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 99ms/step\n","output_type":"stream"},{"name":"stderr","text":" 70%|██████▉   | 434/622 [04:51<02:04,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 70%|██████▉   | 435/622 [04:52<02:03,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 436/622 [04:53<02:03,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 125ms/step\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 437/622 [04:53<02:06,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 438/622 [04:54<02:05,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████   | 439/622 [04:55<02:07,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████   | 440/622 [04:55<02:05,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████   | 441/622 [04:56<02:04,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████   | 442/622 [04:57<02:02,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████   | 443/622 [04:57<02:01,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████▏  | 444/622 [04:58<02:05,  1.41it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 445/622 [04:59<02:02,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 446/622 [05:00<02:06,  1.39it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 447/622 [05:00<02:05,  1.39it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 448/622 [05:01<02:03,  1.41it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 449/622 [05:02<02:03,  1.40it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 450/622 [05:02<02:02,  1.41it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 451/622 [05:03<02:00,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 452/622 [05:04<01:56,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 453/622 [05:04<01:55,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 454/622 [05:05<01:56,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 455/622 [05:06<01:55,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 456/622 [05:07<01:52,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 457/622 [05:07<01:50,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▎  | 458/622 [05:08<01:49,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 110ms/step\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 459/622 [05:09<01:50,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 460/622 [05:09<01:46,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 461/622 [05:10<01:42,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 462/622 [05:10<01:43,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 463/622 [05:11<01:40,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▍  | 464/622 [05:12<01:39,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▍  | 465/622 [05:12<01:38,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▍  | 466/622 [05:13<01:39,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 467/622 [05:14<01:40,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 468/622 [05:14<01:38,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 469/622 [05:15<01:37,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 470/622 [05:15<01:35,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 471/622 [05:16<01:36,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 109ms/step\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 472/622 [05:17<01:38,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 126ms/step\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 473/622 [05:18<01:40,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 126ms/step\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 474/622 [05:18<01:38,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▋  | 475/622 [05:19<01:37,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 476/622 [05:19<01:35,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 477/622 [05:20<01:34,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 478/622 [05:21<01:32,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 479/622 [05:21<01:32,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 480/622 [05:22<01:29,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 481/622 [05:23<01:28,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 109ms/step\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 482/622 [05:23<01:29,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 483/622 [05:24<01:28,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 484/622 [05:25<01:27,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 485/622 [05:25<01:29,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 486/622 [05:26<01:30,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 487/622 [05:27<01:32,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 488/622 [05:27<01:30,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▊  | 489/622 [05:28<01:30,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 490/622 [05:29<01:26,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 491/622 [05:29<01:24,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 492/622 [05:30<01:23,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 493/622 [05:31<01:24,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 494/622 [05:31<01:24,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 80%|███████▉  | 495/622 [05:32<01:24,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 80%|███████▉  | 496/622 [05:33<01:25,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 131ms/step\n","output_type":"stream"},{"name":"stderr","text":" 80%|███████▉  | 497/622 [05:33<01:25,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 498/622 [05:34<01:25,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 499/622 [05:35<01:23,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 500/622 [05:35<01:23,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 501/622 [05:36<01:23,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 502/622 [05:37<01:21,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 503/622 [05:37<01:20,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 504/622 [05:38<01:21,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 505/622 [05:39<01:21,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████▏ | 506/622 [05:39<01:19,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 507/622 [05:40<01:18,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 110ms/step\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 508/622 [05:41<01:16,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 509/622 [05:41<01:14,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 510/622 [05:42<01:12,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 511/622 [05:43<01:13,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 512/622 [05:43<01:12,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 513/622 [05:44<01:11,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 514/622 [05:45<01:08,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 515/622 [05:45<01:07,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 516/622 [05:46<01:06,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 517/622 [05:46<01:05,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 518/622 [05:47<01:04,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 519/622 [05:50<02:13,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▎ | 520/622 [05:51<01:51,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 521/622 [05:51<01:36,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 522/622 [05:52<01:26,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 106ms/step\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 523/622 [05:53<01:19,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 113ms/step\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 524/622 [05:53<01:15,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 525/622 [05:54<01:12,  1.35it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▍ | 526/622 [05:55<01:09,  1.39it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▍ | 527/622 [05:55<01:06,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 110ms/step\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▍ | 528/622 [05:56<01:04,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 529/622 [05:57<01:02,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 530/622 [05:57<01:00,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 531/622 [05:58<00:59,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 532/622 [05:58<00:58,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 533/622 [05:59<00:57,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 534/622 [06:00<00:58,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 535/622 [06:00<00:57,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 536/622 [06:01<00:57,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▋ | 537/622 [06:02<00:54,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▋ | 538/622 [06:02<00:54,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 539/622 [06:03<00:54,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 540/622 [06:04<00:52,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 541/622 [06:04<00:52,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 542/622 [06:05<00:52,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 543/622 [06:06<00:51,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 109ms/step\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 544/622 [06:06<00:51,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 545/622 [06:07<00:49,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 546/622 [06:08<00:48,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 547/622 [06:08<00:48,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 548/622 [06:09<00:48,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 549/622 [06:10<00:47,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 550/622 [06:10<00:46,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▊ | 551/622 [06:11<00:45,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 108ms/step\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▊ | 552/622 [06:11<00:44,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 553/622 [06:12<00:43,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 554/622 [06:13<00:44,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 555/622 [06:13<00:44,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 556/622 [06:14<00:42,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 90%|████████▉ | 557/622 [06:15<00:41,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 90%|████████▉ | 558/622 [06:15<00:42,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 90%|████████▉ | 559/622 [06:16<00:42,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 560/622 [06:17<00:42,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 561/622 [06:17<00:41,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 562/622 [06:18<00:41,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 563/622 [06:19<00:40,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 564/622 [06:20<00:39,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 140ms/step\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 565/622 [06:20<00:41,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 125ms/step\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 566/622 [06:21<00:39,  1.40it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 567/622 [06:22<00:38,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████▏| 568/622 [06:22<00:36,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████▏| 569/622 [06:23<00:36,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 570/622 [06:24<00:34,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 571/622 [06:24<00:33,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 572/622 [06:25<00:32,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 573/622 [06:26<00:32,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 574/622 [06:26<00:31,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 575/622 [06:27<00:31,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 576/622 [06:28<00:30,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 577/622 [06:28<00:30,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 578/622 [06:29<00:29,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 579/622 [06:30<00:29,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 580/622 [06:30<00:27,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 581/622 [06:31<00:27,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▎| 582/622 [06:32<00:26,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▎| 583/622 [06:32<00:25,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 584/622 [06:33<00:24,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 585/622 [06:34<00:24,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 586/622 [06:34<00:23,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 587/622 [06:35<00:23,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 588/622 [06:36<00:22,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 589/622 [06:36<00:22,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 590/622 [06:37<00:22,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 591/622 [06:38<00:21,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 592/622 [06:38<00:20,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 593/622 [06:39<00:19,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 594/622 [06:40<00:19,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 595/622 [06:40<00:18,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 596/622 [06:41<00:17,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 597/622 [06:42<00:17,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 598/622 [06:43<00:16,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 127ms/step\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▋| 599/622 [06:43<00:16,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▋| 600/622 [06:44<00:15,  1.39it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 107ms/step\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 601/622 [06:45<00:14,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 602/622 [06:45<00:13,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 603/622 [06:46<00:12,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 109ms/step\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 604/622 [06:47<00:12,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 605/622 [06:47<00:11,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 606/622 [06:48<00:10,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 607/622 [06:48<00:09,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 608/622 [06:49<00:08,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 104ms/step\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 609/622 [06:50<00:08,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 610/622 [06:51<00:07,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 100ms/step\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 611/622 [06:51<00:07,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 135ms/step\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 612/622 [06:52<00:06,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 127ms/step\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▊| 613/622 [06:53<00:06,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 112ms/step\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▊| 614/622 [06:53<00:05,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▉| 615/622 [06:54<00:04,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▉| 616/622 [06:55<00:04,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▉| 617/622 [06:55<00:03,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▉| 618/622 [06:56<00:02,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 619/622 [06:57<00:01,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 103ms/step\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 620/622 [06:57<00:01,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 101ms/step\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 621/622 [06:58<00:00,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Image shape: (1, 256, 256, 3), Mask shape: (256, 256, 1)\n1/1 [==============================] - 0s 102ms/step\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 622/622 [06:59<00:00,  1.48it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\n\n\nfolder_to_zip = \"results_UNET_TR_v3\"\nzip_filename = \"results_UNET_TR_v3.zip\"\n\n\nshutil.make_archive(folder_to_zip, 'zip', folder_to_zip)\n\nfrom IPython.display import FileLink\nFileLink(zip_filename)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T08:52:22.296905Z","iopub.execute_input":"2024-07-25T08:52:22.297393Z","iopub.status.idle":"2024-07-25T08:52:27.288951Z","shell.execute_reply.started":"2024-07-25T08:52:22.297358Z","shell.execute_reply":"2024-07-25T08:52:27.287638Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/results_UNET_TR_v3.zip","text/html":"<a href='results_UNET_TR_v3.zip' target='_blank'>results_UNET_TR_v3.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}